{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_results_dir = os.path.join(os.getcwd(), os.pardir, \"saved_models\", \"torch\")\n",
    "torch_results_files = [os.path.join(torch_results_dir, f, \"results.json\") for f in os.listdir(torch_results_dir)]\n",
    "\n",
    "keras_results_dir = os.path.join(os.getcwd(), os.pardir, \"saved_models\", \"keras\")\n",
    "keras_results_files = [os.path.join(keras_results_dir, f, \"results.json\") for f in os.listdir(keras_results_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch_files = []\n",
    "\n",
    "# for f in torch_results_files:\n",
    "#     if \"scibert\" in f:\n",
    "#         sub_folder = f.split(\"results.json\")[0]\n",
    "#         sub_files = os.listdir(sub_folder)\n",
    "#         print(sub_folder)\n",
    "#         sub_files = [os.path.join(f, sf, \"results.json\") for sf in sub_files]\n",
    "#         for sf in sub_files:\n",
    "#             torch_files.append(sf)\n",
    "#     else:\n",
    "#         torch_files.append(f)\n",
    "\n",
    "# torch_results_files = torch_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_to_df(files, _type):\n",
    "    \n",
    "    type_mapping = {\"torch\": [\"model_version\", [\"lemmatize\", \"balance_dataset\", \"shuffle_data\", \"epochs\", \"batch_size\", \"learning_rate\", \"max_len\", \"bfloat16\"]], \n",
    "                \"keras\": [\"embedding_type\", [\"lemmatize\", \"balance_dataset\", \"number_of_epochs\", \"batch_size\", \"learning_rate\", \"max_len\"]]}\n",
    "    model_type, params = type_mapping[_type]\n",
    "    \n",
    "    results = []\n",
    "    for file in files:\n",
    "\n",
    "        if not os.path.isfile(file):\n",
    "            continue\n",
    "        with open(file, \"r\") as f:\n",
    "            res = json.load(f)\n",
    "            res[\"model\"] = [x for x in file.split(\"&\") if model_type in x][0].split(\"=\")[-1]\n",
    "\n",
    "            config = configparser.ConfigParser()\n",
    "            config.read(file.replace(\"results.json\", \"config.txt\"))\n",
    "\n",
    "            for param in params:\n",
    "                res[param] = config[\"param\"][param]\n",
    "\n",
    "            results.append(res)\n",
    "            # break\n",
    "    \n",
    "    headers = [\"precision\", \"recall\", \"f1-score\", \"0_precision\", \"0_recall\", \"0_f1-score\", \"1_precision\", \"1_recall\", \"1_f1-score\", \"2_precision\", \"2_recall\", \"2_f1-score\"]\n",
    "    mapping = {\"precision\": \"p\", \"recall\": \"r\", \"f1-score\": \"f1\", \"0-precision\": \"0-p\", \"0-recall\": \"0-r\", \"0-f1-score\": \"0-f1\", \"1-precision\": \"1-p\", \"1-recall\": \"1-r\", \"1-f1-score\": \"1-f1\", \"2-precision\": \"2-p\", \"2-recall\": \"2-r\", \"2-f1-score\": \"2-f1\", \"model\": \"model\", \"lemmatize\": \"l\", \"balance_dataset\": \"b\", \"shuffle_data\": \"s\", \"epochs\": \"epoch\", \"number_of_epochs\": \"epoch\", \"batch_size\": \"batch\", \"learning_rate\": \"lr\", \"max_len\": \"len\", \"bfloat16\": \"bf16\"}\n",
    "    \n",
    "    result_table = defaultdict(list)\n",
    "\n",
    "    for result in results:\n",
    "        result_table[mapping[\"model\"]].append(result[\"model\"])\n",
    "        result_table[mapping[\"lemmatize\"]].append(result[\"lemmatize\"][0])\n",
    "        result_table[mapping[\"balance_dataset\"]].append(result[\"balance_dataset\"][0])\n",
    "        if _type == \"torch\":\n",
    "            result_table[mapping[\"shuffle_data\"]].append(result[\"shuffle_data\"][0])\n",
    "            result_table[mapping[\"bfloat16\"]].append(result[\"bfloat16\"][0])\n",
    "            result_table[mapping[\"epochs\"]].append(result[\"epochs\"])\n",
    "        elif _type == \"keras\":\n",
    "            result_table[mapping[\"number_of_epochs\"]].append(result[\"number_of_epochs\"])\n",
    "        result_table[mapping[\"batch_size\"]].append(result[\"batch_size\"])\n",
    "        result_table[mapping[\"learning_rate\"]].append(result[\"learning_rate\"])\n",
    "        result_table[mapping[\"max_len\"]].append(result[\"max_len\"])\n",
    "        for header in headers:\n",
    "            if \"_\" in header:\n",
    "                _class,_metric = header.split(\"_\")\n",
    "                if _type == \"keras\":\n",
    "#                     _class = str(int(_class)+2)\n",
    "                    score = result[str(int(_class)+2)][_metric]\n",
    "                else:\n",
    "                    score = result[_class][_metric]\n",
    "                result_table[mapping[_class+\"-\"+_metric]].append(round(score, 3))\n",
    "            else:\n",
    "                _metric = header\n",
    "                score = result[\"macro avg\"][_metric]\n",
    "                result_table[mapping[_metric]].append(round(score, 3))\n",
    "                \n",
    "    return pd.DataFrame(result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "      <th>0-p</th>\n",
       "      <th>0-r</th>\n",
       "      <th>0-f1</th>\n",
       "      <th>1-p</th>\n",
       "      <th>1-r</th>\n",
       "      <th>1-f1</th>\n",
       "      <th>2-p</th>\n",
       "      <th>2-r</th>\n",
       "      <th>2-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allenai+scibert_scivocab_uncased</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allenai+scibert_scivocab_cased</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>allenai+scibert_scivocab_cased</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>allenai+scibert_scivocab_uncased</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>allenai+scibert_scivocab_uncased</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>allenai+scibert_scivocab_cased</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model     f1    0-p    0-r   0-f1    1-p  \\\n",
       "0                     albert-base-v2  0.810  0.837  0.787  0.811  0.853   \n",
       "1   allenai+scibert_scivocab_uncased  0.828  0.887  0.779  0.829  0.859   \n",
       "2     allenai+scibert_scivocab_cased  0.782  0.841  0.833  0.837  0.923   \n",
       "3                    bert-base-cased  0.757  0.877  0.767  0.818  0.904   \n",
       "4                    bert-base-cased  0.805  0.826  0.825  0.825  0.897   \n",
       "5                  bert-base-uncased  0.819  0.856  0.797  0.825  0.874   \n",
       "6                    bert-base-cased  0.843  0.865  0.815  0.839  0.887   \n",
       "7                     albert-base-v2  0.742  0.684  0.889  0.774  0.954   \n",
       "8     allenai+scibert_scivocab_cased  0.821  0.824  0.858  0.840  0.913   \n",
       "9                  bert-base-uncased  0.760  0.781  0.864  0.821  0.945   \n",
       "10                 bert-base-uncased  0.769  0.775  0.843  0.808  0.922   \n",
       "11                    albert-base-v2  0.705  0.695  0.876  0.775  0.950   \n",
       "12                   bert-base-cased  0.759  0.824  0.816  0.820  0.902   \n",
       "13                 bert-base-uncased  0.770  0.782  0.835  0.807  0.888   \n",
       "14                   bert-base-cased  0.756  0.828  0.818  0.823  0.923   \n",
       "15  allenai+scibert_scivocab_uncased  0.788  0.835  0.818  0.826  0.919   \n",
       "16  allenai+scibert_scivocab_uncased  0.815  0.891  0.783  0.834  0.884   \n",
       "17                    albert-base-v2  0.826  0.828  0.793  0.810  0.858   \n",
       "18                   bert-base-cased  0.737  0.839  0.759  0.797  0.879   \n",
       "19    allenai+scibert_scivocab_cased  0.756  0.739  0.869  0.799  0.940   \n",
       "20                    albert-base-v2  0.812  0.814  0.818  0.816  0.839   \n",
       "\n",
       "      1-r   1-f1    2-p    2-r   2-f1  \n",
       "0   0.845  0.849  0.711  0.838  0.770  \n",
       "1   0.876  0.867  0.720  0.873  0.789  \n",
       "2   0.736  0.819  0.535  0.965  0.689  \n",
       "3   0.732  0.809  0.480  0.973  0.643  \n",
       "4   0.794  0.843  0.631  0.911  0.746  \n",
       "5   0.846  0.860  0.686  0.884  0.772  \n",
       "6   0.858  0.872  0.733  0.923  0.817  \n",
       "7   0.610  0.744  0.564  0.954  0.709  \n",
       "8   0.787  0.845  0.660  0.946  0.778  \n",
       "9   0.667  0.782  0.518  0.977  0.677  \n",
       "10  0.704  0.799  0.557  0.950  0.702  \n",
       "11  0.557  0.702  0.481  0.954  0.639  \n",
       "12  0.710  0.794  0.512  0.942  0.663  \n",
       "13  0.747  0.812  0.582  0.846  0.690  \n",
       "14  0.694  0.792  0.491  0.973  0.653  \n",
       "15  0.762  0.833  0.558  0.950  0.703  \n",
       "16  0.836  0.859  0.628  0.938  0.752  \n",
       "17  0.861  0.859  0.776  0.842  0.807  \n",
       "18  0.712  0.787  0.474  0.927  0.627  \n",
       "19  0.664  0.778  0.546  0.938  0.690  \n",
       "20  0.865  0.852  0.823  0.718  0.767  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_df[[\"model\", \"f1\", \"0-p\", \"0-r\", \"0-f1\", \"1-p\", \"1-r\", \"1-f1\", \"2-p\", \"2-r\", \"2-f1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allenai+scibert_scivocab_uncased</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allenai+scibert_scivocab_cased</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>allenai+scibert_scivocab_cased</td>\n",
       "      <td>0.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>allenai+scibert_scivocab_uncased</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>allenai+scibert_scivocab_uncased</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>allenai+scibert_scivocab_cased</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model     f1\n",
       "0                     albert-base-v2  0.810\n",
       "1   allenai+scibert_scivocab_uncased  0.828\n",
       "2     allenai+scibert_scivocab_cased  0.782\n",
       "3                    bert-base-cased  0.757\n",
       "4                    bert-base-cased  0.805\n",
       "5                  bert-base-uncased  0.819\n",
       "6                    bert-base-cased  0.843\n",
       "7                     albert-base-v2  0.742\n",
       "8     allenai+scibert_scivocab_cased  0.821\n",
       "9                  bert-base-uncased  0.760\n",
       "10                 bert-base-uncased  0.769\n",
       "11                    albert-base-v2  0.705\n",
       "12                   bert-base-cased  0.759\n",
       "13                 bert-base-uncased  0.770\n",
       "14                   bert-base-cased  0.756\n",
       "15  allenai+scibert_scivocab_uncased  0.788\n",
       "16  allenai+scibert_scivocab_uncased  0.815\n",
       "17                    albert-base-v2  0.826\n",
       "18                   bert-base-cased  0.737\n",
       "19    allenai+scibert_scivocab_cased  0.756\n",
       "20                    albert-base-v2  0.812"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_df = result_to_df(torch_results_files, \"torch\")\n",
    "torch_df[[\"model\", \"f1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>l</th>\n",
       "      <th>b</th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>lr</th>\n",
       "      <th>len</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f1</th>\n",
       "      <th>0-p</th>\n",
       "      <th>0-r</th>\n",
       "      <th>0-f1</th>\n",
       "      <th>1-p</th>\n",
       "      <th>1-r</th>\n",
       "      <th>1-f1</th>\n",
       "      <th>2-p</th>\n",
       "      <th>2-r</th>\n",
       "      <th>2-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm/results.json</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>albert/results.json</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.99</td>\n",
       "      <td>50</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.325</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstm/results.json</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lstm/results.json</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lstm/results.json</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lstm/results.json</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lstm/results.json</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lstm/results.json</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lstm/results.json</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lstm/results.json</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bert/results.json</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.99</td>\n",
       "      <td>50</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lstm/results.json</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.99</td>\n",
       "      <td>50</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lstm/results.json</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lstm/results.json</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lstm/results.json</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lstm/results.json</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lstm/results.json</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lstm/results.json</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lstm/results.json</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  l  b epoch batch    lr  len      p      r     f1  \\\n",
       "0     lstm/results.json  T  F     5    64  0.99  100  0.739  0.760  0.748   \n",
       "1   albert/results.json  F  F     5    64  0.99   50  0.108  0.333  0.164   \n",
       "2     lstm/results.json  F  F     5    64  0.99  100  0.782  0.756  0.767   \n",
       "3     lstm/results.json  F  F     5    64  0.99  100  0.712  0.723  0.714   \n",
       "4     lstm/results.json  F  F     5    64  0.99  100  0.739  0.748  0.742   \n",
       "5     lstm/results.json  F  F    20    64  0.99  100  0.676  0.697  0.684   \n",
       "6     lstm/results.json  T  F    20    64  0.99  100  0.711  0.741  0.723   \n",
       "7     lstm/results.json  F  F    20    64  0.99  100  0.704  0.728  0.712   \n",
       "8     lstm/results.json  T  F     5    64  0.99  100  0.769  0.725  0.743   \n",
       "9     lstm/results.json  F  F    20    64  0.99  100  0.727  0.673  0.693   \n",
       "10    bert/results.json  F  F     5     4  0.99   50  0.718  0.535  0.544   \n",
       "11    lstm/results.json  F  F     5    64  0.99   50  0.732  0.737  0.733   \n",
       "12    lstm/results.json  F  F    20    64  0.99  100  0.660  0.664  0.659   \n",
       "13    lstm/results.json  T  F     5    64  0.99  100  0.748  0.776  0.760   \n",
       "14    lstm/results.json  F  F     5    64  0.99  100  0.746  0.756  0.750   \n",
       "15    lstm/results.json  F  F     5    64  0.99  100  0.727  0.760  0.738   \n",
       "16    lstm/results.json  F  F     5    64  0.99  100  0.719  0.749  0.731   \n",
       "17    lstm/results.json  F  F     5    64  0.99  100  0.739  0.720  0.728   \n",
       "18    lstm/results.json  T  F    20    64  0.99  100  0.695  0.710  0.702   \n",
       "\n",
       "      0-p    0-r   0-f1    1-p    1-r   1-f1    2-p    2-r   2-f1  \n",
       "0   0.855  0.772  0.811  0.725  0.810  0.765  0.637  0.699  0.667  \n",
       "1   0.000  0.000  0.000  0.325  1.000  0.491  0.000  0.000  0.000  \n",
       "2   0.803  0.852  0.827  0.803  0.764  0.783  0.738  0.653  0.693  \n",
       "3   0.783  0.808  0.795  0.789  0.673  0.726  0.565  0.687  0.620  \n",
       "4   0.798  0.814  0.806  0.786  0.716  0.749  0.634  0.714  0.672  \n",
       "5   0.767  0.747  0.757  0.727  0.688  0.707  0.535  0.656  0.589  \n",
       "6   0.815  0.754  0.783  0.742  0.759  0.750  0.577  0.710  0.637  \n",
       "7   0.791  0.772  0.782  0.785  0.714  0.748  0.536  0.699  0.606  \n",
       "8   0.782  0.867  0.822  0.796  0.721  0.756  0.731  0.587  0.651  \n",
       "9   0.745  0.854  0.795  0.765  0.663  0.710  0.670  0.502  0.574  \n",
       "10  0.665  0.969  0.789  0.879  0.527  0.659  0.609  0.108  0.184  \n",
       "11  0.794  0.819  0.807  0.810  0.717  0.761  0.591  0.676  0.631  \n",
       "12  0.744  0.784  0.764  0.717  0.602  0.654  0.520  0.606  0.560  \n",
       "13  0.839  0.774  0.805  0.765  0.808  0.786  0.639  0.745  0.688  \n",
       "14  0.806  0.818  0.812  0.798  0.732  0.764  0.635  0.718  0.674  \n",
       "15  0.818  0.791  0.804  0.796  0.716  0.754  0.568  0.772  0.655  \n",
       "16  0.835  0.735  0.782  0.705  0.795  0.747  0.618  0.718  0.664  \n",
       "17  0.782  0.844  0.812  0.799  0.714  0.754  0.637  0.602  0.619  \n",
       "18  0.792  0.759  0.775  0.731  0.745  0.738  0.562  0.625  0.592  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_df = result_to_df(keras_results_files, \"keras\")\n",
    "keras_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.to_latex(columns=['model', 'p', 'r',\n",
    "       'f1', '0-p', '0-r', '0-f1', '1-p', '1-r', '1-f1', '2-p', '2-r', '2-f1'], index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "de",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "de",
   "useGoogleTranslate": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
