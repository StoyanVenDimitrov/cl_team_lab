{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitvenvvenv6a9f05ce78444862ade060e069e9e39d",
   "display_name": "Python 3.8.2 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = os.path.join(os.getcwd(), os.pardir, \"saved_models\", \"torch\")\n",
    "results_files = [os.path.join(results_dir, f, \"results.json\") for f in os.listdir(results_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for file in results_files:\n",
    "\n",
    "    if not os.path.isfile(file):\n",
    "        continue\n",
    "    with open(file, \"r\") as f:\n",
    "        res = json.load(f)\n",
    "        res[\"model\"] = [x for x in file.split(\"&\") if \"model_version\" in x][0].split(\"=\")[-1]\n",
    "        \n",
    "        config = configparser.ConfigParser()\n",
    "        config.read(file.replace(\"results.json\", \"config.txt\"))\n",
    "\n",
    "        for param in [\"lemmatize\", \"balance_dataset\", \"shuffle_data\", \"epochs\", \"batch_size\", \"learning_rate\", \"max_len\", \"bfloat16\"]:\n",
    "            res[param] = config[\"param\"][param]\n",
    "\n",
    "        results.append(res)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"precision\", \"recall\", \"f1-score\", \"0_precision\", \"0_recall\", \"0_f1-score\", \"1_precision\", \"1_recall\", \"1_f1-score\", \"2_precision\", \"2_recall\", \"2_f1-score\"]\n",
    "\n",
    "mapping = {\"precision\": \"p\", \"recall\": \"r\", \"f1-score\": \"f1\", \"0-precision\": \"0-p\", \"0-recall\": \"0-r\", \"0-f1-score\": \"0-f1\", \"1-precision\": \"1-p\", \"1-recall\": \"1-r\", \"1-f1-score\": \"1-f1\", \"2-precision\": \"2-p\", \"2-recall\": \"2-r\", \"2-f1-score\": \"2-f1\", \"model\": \"model\", \"lemmatize\": \"l\", \"balance_dataset\": \"b\", \"shuffle_data\": \"s\", \"epochs\": \"epoch\", \"batch_size\": \"batch\", \"learning_rate\": \"lr\", \"max_len\": \"len\", \"bfloat16\": \"bf16\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table = defaultdict(list)\n",
    "\n",
    "for result in results:\n",
    "    result_table[mapping[\"model\"]].append(result[\"model\"])\n",
    "    result_table[mapping[\"lemmatize\"]].append(result[\"lemmatize\"][0])\n",
    "    result_table[mapping[\"balance_dataset\"]].append(result[\"balance_dataset\"][0])\n",
    "    result_table[mapping[\"shuffle_data\"]].append(result[\"shuffle_data\"][0])\n",
    "    result_table[mapping[\"epochs\"]].append(result[\"epochs\"])\n",
    "    result_table[mapping[\"batch_size\"]].append(result[\"batch_size\"])\n",
    "    result_table[mapping[\"learning_rate\"]].append(result[\"learning_rate\"])\n",
    "    result_table[mapping[\"max_len\"]].append(result[\"max_len\"])\n",
    "    result_table[mapping[\"bfloat16\"]].append(result[\"bfloat16\"][0])\n",
    "    for header in headers:\n",
    "        if \"_\" in header:\n",
    "            _class,_metric = header.split(\"_\")\n",
    "            score = result[_class][_metric]\n",
    "            result_table[mapping[_class+\"-\"+_metric]].append(round(score, 3))\n",
    "        else:\n",
    "            _metric = header\n",
    "            score = result[\"macro avg\"][_metric]\n",
    "            result_table[mapping[_metric]].append(round(score, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "defaultdict(list,\n            {'model': ['albert-base-v2',\n              'albert-base-v2',\n              'albert-base-v2',\n              'bert-base-uncased',\n              'albert-base-v2'],\n             'l': ['F', 'F', 'F', 'F', 'F'],\n             'b': ['F', 'F', 'T', 'T', 'F'],\n             's': ['T', 'F', 'F', 'F', 'F'],\n             'epoch': ['5', '5', '5', '5', '5'],\n             'batch': ['8', '8', '8', '8', '8'],\n             'lr': ['1e-5', '1e-5', '1e-5', '1e-5', '5e-6'],\n             'len': ['50', '50', '100', '50', '100'],\n             'bf16': ['T', 'T', 'T', 'T', 'T'],\n             'p': [0.82, 0.814, 0.829, 0.818, 0.791],\n             'r': [0.822, 0.827, 0.82, 0.79, 0.835],\n             'f1': [0.817, 0.82, 0.817, 0.789, 0.807],\n             '0-p': [0.89, 0.83, 0.865, 0.934, 0.842],\n             '0-r': [0.735, 0.816, 0.815, 0.71, 0.795],\n             '0-f1': [0.805, 0.823, 0.839, 0.807, 0.818],\n             '1-p': [0.833, 0.862, 0.864, 0.832, 0.878],\n             '1-r': [0.89, 0.851, 0.687, 0.687, 0.827],\n             '1-f1': [0.86, 0.857, 0.766, 0.753, 0.852],\n             '2-p': [0.736, 0.751, 0.758, 0.689, 0.654],\n             '2-r': [0.842, 0.815, 0.958, 0.973, 0.884],\n             '2-f1': [0.786, 0.781, 0.846, 0.806, 0.752]})"
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               model  l  b  s epoch batch    lr  len bf16      p  ...     f1  \\\n0     albert-base-v2  F  F  T     5     8  1e-5   50    T  0.820  ...  0.817   \n1     albert-base-v2  F  F  F     5     8  1e-5   50    T  0.814  ...  0.820   \n2     albert-base-v2  F  T  F     5     8  1e-5  100    T  0.829  ...  0.817   \n3  bert-base-uncased  F  T  F     5     8  1e-5   50    T  0.818  ...  0.789   \n4     albert-base-v2  F  F  F     5     8  5e-6  100    T  0.791  ...  0.807   \n\n     0-p    0-r   0-f1    1-p    1-r   1-f1    2-p    2-r   2-f1  \n0  0.890  0.735  0.805  0.833  0.890  0.860  0.736  0.842  0.786  \n1  0.830  0.816  0.823  0.862  0.851  0.857  0.751  0.815  0.781  \n2  0.865  0.815  0.839  0.864  0.687  0.766  0.758  0.958  0.846  \n3  0.934  0.710  0.807  0.832  0.687  0.753  0.689  0.973  0.806  \n4  0.842  0.795  0.818  0.878  0.827  0.852  0.654  0.884  0.752  \n\n[5 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>l</th>\n      <th>b</th>\n      <th>s</th>\n      <th>epoch</th>\n      <th>batch</th>\n      <th>lr</th>\n      <th>len</th>\n      <th>bf16</th>\n      <th>p</th>\n      <th>...</th>\n      <th>f1</th>\n      <th>0-p</th>\n      <th>0-r</th>\n      <th>0-f1</th>\n      <th>1-p</th>\n      <th>1-r</th>\n      <th>1-f1</th>\n      <th>2-p</th>\n      <th>2-r</th>\n      <th>2-f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>albert-base-v2</td>\n      <td>F</td>\n      <td>F</td>\n      <td>T</td>\n      <td>5</td>\n      <td>8</td>\n      <td>1e-5</td>\n      <td>50</td>\n      <td>T</td>\n      <td>0.820</td>\n      <td>...</td>\n      <td>0.817</td>\n      <td>0.890</td>\n      <td>0.735</td>\n      <td>0.805</td>\n      <td>0.833</td>\n      <td>0.890</td>\n      <td>0.860</td>\n      <td>0.736</td>\n      <td>0.842</td>\n      <td>0.786</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>albert-base-v2</td>\n      <td>F</td>\n      <td>F</td>\n      <td>F</td>\n      <td>5</td>\n      <td>8</td>\n      <td>1e-5</td>\n      <td>50</td>\n      <td>T</td>\n      <td>0.814</td>\n      <td>...</td>\n      <td>0.820</td>\n      <td>0.830</td>\n      <td>0.816</td>\n      <td>0.823</td>\n      <td>0.862</td>\n      <td>0.851</td>\n      <td>0.857</td>\n      <td>0.751</td>\n      <td>0.815</td>\n      <td>0.781</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>albert-base-v2</td>\n      <td>F</td>\n      <td>T</td>\n      <td>F</td>\n      <td>5</td>\n      <td>8</td>\n      <td>1e-5</td>\n      <td>100</td>\n      <td>T</td>\n      <td>0.829</td>\n      <td>...</td>\n      <td>0.817</td>\n      <td>0.865</td>\n      <td>0.815</td>\n      <td>0.839</td>\n      <td>0.864</td>\n      <td>0.687</td>\n      <td>0.766</td>\n      <td>0.758</td>\n      <td>0.958</td>\n      <td>0.846</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bert-base-uncased</td>\n      <td>F</td>\n      <td>T</td>\n      <td>F</td>\n      <td>5</td>\n      <td>8</td>\n      <td>1e-5</td>\n      <td>50</td>\n      <td>T</td>\n      <td>0.818</td>\n      <td>...</td>\n      <td>0.789</td>\n      <td>0.934</td>\n      <td>0.710</td>\n      <td>0.807</td>\n      <td>0.832</td>\n      <td>0.687</td>\n      <td>0.753</td>\n      <td>0.689</td>\n      <td>0.973</td>\n      <td>0.806</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>albert-base-v2</td>\n      <td>F</td>\n      <td>F</td>\n      <td>F</td>\n      <td>5</td>\n      <td>8</td>\n      <td>5e-6</td>\n      <td>100</td>\n      <td>T</td>\n      <td>0.791</td>\n      <td>...</td>\n      <td>0.807</td>\n      <td>0.842</td>\n      <td>0.795</td>\n      <td>0.818</td>\n      <td>0.878</td>\n      <td>0.827</td>\n      <td>0.852</td>\n      <td>0.654</td>\n      <td>0.884</td>\n      <td>0.752</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\\begin{tabular}{lrrrrrrrrrrrr}\n\\toprule\n             model &      p &      r &     f1 &    0-p &    0-r &   0-f1 &    1-p &    1-r &   1-f1 &    2-p &    2-r &   2-f1 \\\\\n\\midrule\n    albert-base-v2 &  0.820 &  0.822 &  0.817 &  0.890 &  0.735 &  0.805 &  0.833 &  0.890 &  0.860 &  0.736 &  0.842 &  0.786 \\\\\n    albert-base-v2 &  0.814 &  0.827 &  0.820 &  0.830 &  0.816 &  0.823 &  0.862 &  0.851 &  0.857 &  0.751 &  0.815 &  0.781 \\\\\n    albert-base-v2 &  0.829 &  0.820 &  0.817 &  0.865 &  0.815 &  0.839 &  0.864 &  0.687 &  0.766 &  0.758 &  0.958 &  0.846 \\\\\n bert-base-uncased &  0.818 &  0.790 &  0.789 &  0.934 &  0.710 &  0.807 &  0.832 &  0.687 &  0.753 &  0.689 &  0.973 &  0.806 \\\\\n    albert-base-v2 &  0.791 &  0.835 &  0.807 &  0.842 &  0.795 &  0.818 &  0.878 &  0.827 &  0.852 &  0.654 &  0.884 &  0.752 \\\\\n\\bottomrule\n\\end{tabular}\n\n"
    }
   ],
   "source": [
    "print(df.to_latex(columns=['model', 'p', 'r',\n",
    "       'f1', '0-p', '0-r', '0-f1', '1-p', '1-r', '1-f1', '2-p', '2-r', '2-f1'], index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['model', 'l', 'b', 's', 'epoch', 'batch', 'lr', 'len', 'bf16', 'p', 'r',\n       'f1', '0-p', '0-r', '0-f1', '1-p', '1-r', '1-f1', '2-p', '2-r', '2-f1'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}